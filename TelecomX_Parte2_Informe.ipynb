{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# üìò Telecom X ‚Äì Parte 2: Predicci√≥n de Cancelaci√≥n (Churn)\n\n## √çndice\n1. **PREPARACI√ìN DE DATOS**\n2. **CORRELACI√ìN Y SELECCI√ìN DE VARIABLES**\n3. **MODELO PREDICTIVO**\n4. **INTERPRETACI√ìN Y CONCLUSIONES**\n5. **INFORME FINAL**\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## PREPARACI√ìN DE DATOS"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "import pandas as pd\nfrom pathlib import Path\n\ncandidates = [\n    'TelecomX_Data_Modelo_Encoded.csv',\n    '/mnt/data/TelecomX_Data_Modelo_Encoded.csv',\n    'TelecomX_Data_Modelo_Base.csv',\n    '/mnt/data/TelecomX_Data_Modelo_Base.csv',\n    'TelecomX_Data_Estandarizado.csv',\n    '/mnt/data/TelecomX_Data_Estandarizado.csv',\n]\npath = None\nfor p in candidates:\n    if Path(p).exists():\n        path = p\n        break\nassert path is not None, \"No se encontr√≥ un CSV v√°lido.\"\nprint(\"Usando:\", path)\n\ndf = pd.read_csv(path)\nif 'Evasion' in df.columns and df.drop(columns=['Evasion']).select_dtypes(include=['object']).shape[1] > 0:\n    cat_cols = df.drop(columns=['Evasion']).select_dtypes(include=['object']).columns.tolist()\n    print(\"One-hot al vuelo para:\", cat_cols)\n    X = pd.get_dummies(df.drop(columns=['Evasion']), columns=cat_cols, drop_first=True)\n    y = df['Evasion'].astype(int)\nelse:\n    X = df.drop(columns=['Evasion'])\n    y = df['Evasion'].astype(int)\n\nprint(\"X:\", X.shape, \" y:\", y.shape)\ny.value_counts(normalize=True).round(3)"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.30, random_state=42, stratify=y\n)\n(X_train.shape, X_test.shape)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## CORRELACI√ìN Y SELECCI√ìN DE VARIABLES"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\n\ncorr = pd.concat([X, y], axis=1).corr(numeric_only=True)\ntarget_corr = corr['Evasion'].drop(labels=['Evasion']).sort_values(key=lambda s: s.abs(), ascending=False)\nprint(\"Top correlaciones con Evasion:\")\nprint(target_corr.head(15))\n\nplt.figure(figsize=(10,7))\nplt.imshow(corr, aspect='auto')\nplt.colorbar()\nplt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\nplt.yticks(range(len(corr.index)), corr.index)\nplt.title('Matriz de correlaci√≥n')\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## MODELO PREDICTIVO"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\n\npipe_logreg = Pipeline([\n    ('scaler', StandardScaler()),\n    ('clf', LogisticRegression(max_iter=500, class_weight='balanced', solver='liblinear'))\n])\nrf = RandomForestClassifier(n_estimators=300, random_state=42, class_weight='balanced', n_jobs=-1)\n\npipe_logreg.fit(X_train, y_train)\nrf.fit(X_train, y_train)\n\ny_pred_log = pipe_logreg.predict(X_test)\ny_proba_log = pipe_logreg.predict_proba(X_test)[:,1]\ny_pred_rf  = rf.predict(X_test)\ny_proba_rf = rf.predict_proba(X_test)[:,1]\n\n'modelos entrenados'"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef evaluar_modelo(nombre, y_true, y_pred, y_proba):\n    print(f\"\\n=== {nombre} ===\")\n    print(\"Accuracy:\", round(accuracy_score(y_true, y_pred), 3))\n    print(\"Precision:\", round(precision_score(y_true, y_pred), 3))\n    print(\"Recall:\", round(recall_score(y_true, y_pred), 3))\n    print(\"F1-score:\", round(f1_score(y_true, y_pred), 3))\n    print(\"AUC-ROC:\", round(roc_auc_score(y_true, y_proba), 3))\n    print(\"\\nReporte:\\n\", classification_report(y_true, y_pred, digits=3, zero_division=0))\n\n    cm = confusion_matrix(y_true, y_pred)\n    fig = plt.figure(figsize=(5,4))\n    ax = fig.add_subplot(111)\n    im = ax.imshow(cm, interpolation='nearest')\n    fig.colorbar(im)\n    ax.set_title(f\"Matriz de Confusi√≥n - {nombre}\")\n    ax.set_xlabel(\"Predicci√≥n\"); ax.set_ylabel(\"Real\")\n    ax.set_xticks([0,1]); ax.set_xticklabels(['0','1'])\n    ax.set_yticks([0,1]); ax.set_yticklabels(['0','1'])\n    for (i,j), v in np.ndenumerate(cm):\n        ax.text(j, i, str(v), ha='center', va='center')\n    plt.tight_layout(); plt.show()\n\nevaluar_modelo('Regresi√≥n Log√≠stica', y_test, y_pred_log, y_proba_log)\nevaluar_modelo('Random Forest', y_test, y_pred_rf, y_proba_rf)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## INTERPRETACI√ìN Y CONCLUSIONES"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\n\nlog_coefs = pd.Series(pipe_logreg.named_steps['clf'].coef_[0], index=X_train.columns).sort_values(key=np.abs, ascending=False)\nrf_imp = pd.Series(rf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n\nprint(\"Top 15 | Coeficientes absolutos (LogReg):\")\ndisplay(log_coefs.head(15).to_frame('coeficiente'))\n\nprint(\"\\nTop 15 | Importancias (Random Forest):\")\ndisplay(rf_imp.head(15).to_frame('importancia'))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## INFORME FINAL\n\n**Resumen ejecutivo**\n- Se entrenaron y evaluaron dos modelos (Regresi√≥n Log√≠stica con escalado y Random Forest sin escalado).\n- La clase objetivo est√° desbalanceada; se us√≥ estratificaci√≥n y `class_weight='balanced'`.\n- El an√°lisis de importancia sugiere la relevancia de **antig√ºedad (MesesContrato)**, **tipo de contrato** y **cargos mensuales**.\n\n**Recomendaciones**\n- Retenci√≥n temprana para clientes con baja antig√ºedad y contrato mensual.\n- Ajustes de plan/precio para cargos altos.\n- Promover servicios de valor (Seguridad/Soporte).\n- Despliegue del score de churn para campa√±as proactivas.\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}